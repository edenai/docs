# Getting Started with Universal AI

The Universal AI endpoint is the core of Eden AI V3, providing a single unified endpoint for all non-LLM AI features.

## Overview

Instead of calling different endpoints for different features, V3's Universal AI endpoint handles everything through model strings:

```
POST /v3/universal-ai
```

**One endpoint for:**
- Text analysis (moderation, AI detection, embeddings, sentiment)
- OCR (text extraction, invoice/ID parsing)
- Image processing (generation, detection, analysis)
- Translation (document translation)

## Model String Format

The model string tells the endpoint what feature and provider to use:

```
feature/subfeature/provider[/model]
```

**Examples:**
- `text/moderation/google`
- `ocr/financial_parser/google`
- `image/generation/openai/dall-e-3`
- `translation/document_translation/deepl`

## Basic Request

<CodeGroup>
```python Python
import requests

url = "https://api.edenai.run/v3/universal-ai"
headers = {
    "Authorization": "Bearer YOUR_API_KEY",
    "Content-Type": "application/json"
}

payload = {
    "model": "text/moderation/openai",
    "input": {
        "text": "This is sample text to moderate"
    }
}

response = requests.post(url, headers=headers, json=payload)
result = response.json()
print(result)
    ```

```bash cURL
curl -X POST https://api.edenai.run/v3/universal-ai \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "text/moderation/openai",
    "input": {"text": "Sample text"}
  }'
    ```
</CodeGroup>

## Response Format

All Universal AI responses follow the same structure:

```json
{
  "status": "success",
  "cost": 0.0001,
  "provider": "openai",
  "feature": "text",
  "subfeature": "moderation",
  "output": {
    // Feature-specific output
  }
}
```

## Input Formats

The `input` field varies based on the feature:

### Text-Based Features

```json
{
  "model": "text/moderation/google",
  "input": {
    "text": "Text to moderate"
  }
}
```

### File-Based Features (UUID)

```json
{
  "model": "ocr/financial_parser/google",
  "input": {
    "file": "550e8400-e29b-41d4-a716-446655440000"
  }
}
```

### File-Based Features (URL)

```json
{
  "model": "image/object_detection/google",
  "input": {
    "file": "https://example.com/image.jpg"
  }
}
```

## Common Use Cases

### Text Moderation

<CodeGroup>
```python Python
import requests

url = "https://api.edenai.run/v3/universal-ai"
headers = {
    "Authorization": "Bearer YOUR_API_KEY",
    "Content-Type": "application/json"
}

payload = {
    "model": "text/moderation/openai",
    "input": {"text": "Content to moderate"}
}
    
response = requests.post(url, headers=headers, json=payload)
result = response.json()
    
if result["output"]["nsfw_likelihood"] > 3:
    print("Content flagged as inappropriate")
    ```
</CodeGroup>

### OCR Text Extraction

<CodeGroup>
```python Python
import requests

url = "https://api.edenai.run/v3/universal-ai"
headers = {
    "Authorization": "Bearer YOUR_API_KEY",
    "Content-Type": "application/json"
}

# First upload the file
upload_response = requests.post(
    "https://api.edenai.run/v3/upload",
    headers={"Authorization": "Bearer YOUR_API_KEY"},
    files={"file": open("document.pdf", "rb")}
)
file_id = upload_response.json()["file_id"]

# Then use it in Universal AI
payload = {
    "model": "ocr/financial_parser/google",
    "input": {"file": file_id, "language": "en"}
}
    
response = requests.post(url, headers=headers, json=payload)
result = response.json()
print(result["output"]["extracted_data"])
    ```
</CodeGroup>

## Next Steps

- [Text Features](./text-features) - All text analysis capabilities
- [OCR Features](./ocr-features) - Document processing
- [Image Features](./image-features) - Image generation and analysis
- [Multimodal Workflows](./multimodal-features) - Complex processing pipelines
