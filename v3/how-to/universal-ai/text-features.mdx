# Universal AI: Text Features

Use the Universal AI endpoint to access all text analysis features through a single endpoint.

## Available Text Features

| Subfeature | Model String Pattern | Description |
|------------|---------------------|-------------|
| AI Detection | `text/ai_detection/provider/model` | Detect AI-generated content |
| Moderation | `text/moderation/provider` | Content safety and moderation |
| Embeddings | `text/embeddings/provider/model` | Semantic search vectors |
| Sentiment Analysis | `text/sentiment_analysis/provider` | Analyze text sentiment |
| Spell Check | `text/spell_check/provider` | Grammar and spelling correction |
| Named Entity Recognition | `text/ner/provider` | Extract entities from text |
| Topic Extraction | `text/topic_extraction/provider` | Identify main topics |

## AI Detection

Detect whether text was generated by AI:

<CodeGroup>
```python Python
import requests

url = "https://api.edenai.run/v3/universal-ai"
headers = {
    "Authorization": "Bearer YOUR_API_KEY",
    "Content-Type": "application/json"
}

payload = {
    "model": "text/ai_detection/winstonai",
    "input": {
        "text": "Your text to analyze here"
    }
}

response = requests.post(url, headers=headers, json=payload)
result = response.json()

print(f"AI Generated: {result['output']['is_ai_generated']}")
print(f"AI Score: {result['output']['ai_score']}")
    ```
</CodeGroup>

## Content Moderation

Check text for inappropriate content:

<CodeGroup>
```python Python
import requests
payload = {
    "model": "text/moderation/openai",
    "input": {
        "text": "Content to moderate"
    }
}

response = requests.post(url, headers=headers, json=payload)
result = response.json()

print(f"NSFW Likelihood: {result['output']['nsfw_likelihood']}")
for item in result['output']['items']:
    print(f"  {item['label']}: {item['likelihood']}/5")
    ```
</CodeGroup>

## Text Embeddings

Generate semantic vectors for text:

<CodeGroup>
```python Python
import requests
payload = {
    "model": "text/embeddings/openai/text-embedding-3-small",
    "input": {
        "texts": [
            "First text to embed",
            "Second text to embed"
        ]
    }
}

response = requests.post(url, headers=headers, json=payload)
result = response.json()

for i, item in enumerate(result['output']['items']):
    print(f"Text {i+1} embedding: {item['embedding'][:5]}...")
    ```
</CodeGroup>

## Next Steps

- [OCR Features](./ocr-features) - Document processing
- [Image Features](./image-features) - Image capabilities
- [Getting Started](./getting-started) - Universal AI basics
